{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing_and_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "fUcMx2Dysjmr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2 as cv\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.io as sio\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model, Model\n",
        "from keras.layers import InputLayer, Lambda, Conv2D , Dense, Flatten, MaxPooling2D, Dropout, LeakyReLU, Concatenate, BatchNormalization\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.utils import multi_gpu_model\n",
        "from keras.utils import plot_model\n",
        "from keras.layers.merge import concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jhZQrWhUtQzX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-x0IwWlJtTk4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"training.csv\", index_col=0).sample(frac=1,random_state=1)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7imhFJsDtfW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train['x1'] = df_train['x1'].apply(lambda x: x/640)\n",
        "df_train['y1'] = df_train['y1'].apply(lambda x: x/480)\n",
        "df_train['x2'] = df_train['x2'].apply(lambda x: x/640)\n",
        "df_train['y2'] = df_train['y2'].apply(lambda x: x/480)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oy7N34OCtmhF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train['h'] = df_train['y2'] - df_train['y1']\n",
        "df_train['w'] = df_train['x2'] - df_train['x1']\n",
        "df_train['x1'] = (df_train['x1'] + df_train['x2']) / 2\n",
        "df_train['y1'] = (df_train['y1'] + df_train['y2']) / 2\n",
        "df_train = df_train.drop(['x2', 'y2'], axis = 1)\n",
        "y_train = df_train.as_matrix()\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dKl8NK0PtqRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "num_img = 14000\n",
        "data_train = np.zeros(shape=(num_img,480//4,640//4,3))\n",
        "\n",
        "for img_name in df_train.index:\n",
        "    if i >= num_img:\n",
        "        break\n",
        "    img  = cv.imread(\"train_img/\"+img_name,1)\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    data_train[i] = cv.resize(img , (160,120))/255\n",
        "    if i % 500 == 0:\n",
        "        print(\"Progress : \", i/(num_img/100),\"%\")\n",
        "    i +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wy34rkCdtvmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,20))\n",
        "for i in range(20):\n",
        "    plt.subplot(5,4,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(data_train[i], cmap=plt.cm.binary)\n",
        "    plt.grid('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7d8qMsDUuAdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    visible = Input(shape=(120,160,3))\n",
        "\n",
        "\n",
        "    #1\n",
        "    conv1  = Conv2D(32, kernel_size=3,padding='same')(visible)\n",
        "    batch1 = BatchNormalization()(conv1)\n",
        "    leaky1 = LeakyReLU()(batch1)\n",
        "    pool1  = MaxPooling2D(pool_size=(2, 2))(leaky1)\n",
        "\n",
        "    #2\n",
        "    conv2  = Conv2D(64, kernel_size=3,padding='same')(pool1)\n",
        "    batch2 = BatchNormalization()(conv2)\n",
        "    leaky2 = LeakyReLU()(batch2)\n",
        "    pool2  = MaxPooling2D(pool_size=(2, 2))(leaky2)\n",
        "\n",
        "    #3\n",
        "    conv3  = Conv2D(128, kernel_size=3,padding='same')(pool2)\n",
        "    batch3 = BatchNormalization()(conv3)\n",
        "    leaky3 = LeakyReLU()(batch3)\n",
        "    pool3  = MaxPooling2D(pool_size=(2, 2))(leaky3)\n",
        "\n",
        "    #4\n",
        "    conv4  = Conv2D(64, kernel_size=3,padding='same')(pool3)\n",
        "    batch4 = BatchNormalization()(conv4)\n",
        "    leaky4 = LeakyReLU()(batch4)\n",
        "\n",
        "    #5\n",
        "    conv5  = Conv2D(128, kernel_size=3,padding='same')(leaky4)\n",
        "    batch5 = BatchNormalization()(conv5)\n",
        "    leaky5 = LeakyReLU()(batch5)\n",
        "    pool5 = MaxPooling2D(pool_size=(2, 2))(leaky5)\n",
        "    \n",
        "    #6\n",
        "    conv6  = Conv2D(256, kernel_size=3,padding='same')(leaky5)\n",
        "    batch6 = BatchNormalization()(conv6)\n",
        "    leaky6 = LeakyReLU()(batch6)\n",
        "    pool6 = MaxPooling2D(pool_size=(2, 2))(leaky6)\n",
        "\n",
        "    #7\n",
        "    conv7  = Conv2D(128, kernel_size=3,padding='same')(pool6)\n",
        "    batch7 = BatchNormalization()(conv7)\n",
        "    leaky7 = LeakyReLU()(batch7)\n",
        "\n",
        "    #8\n",
        "    conv8  = Conv2D(256, kernel_size=3,padding='same')(leaky7)\n",
        "    batch8 = BatchNormalization()(conv8)\n",
        "    leaky8 = LeakyReLU()(batch8)\n",
        "\n",
        "    #9\n",
        "    conv9  = Conv2D(512, kernel_size=3,padding='same')(leaky8)\n",
        "    batch9 = BatchNormalization()(conv9)\n",
        "    leaky9 = LeakyReLU()(batch9)\n",
        "\n",
        "    #10\n",
        "    conv10  = Conv2D(128, kernel_size=3,padding='same')(leaky9)\n",
        "    batch10 = BatchNormalization()(conv10)\n",
        "    leaky10 = LeakyReLU()(batch10)\n",
        "    \n",
        "    \n",
        "    # branch 2\n",
        "    #10\n",
        "    conv11  = Conv2D(256, kernel_size=3,padding='same')(pool6)\n",
        "    batch11 = BatchNormalization()(conv11)\n",
        "    leaky11 = LeakyReLU()(batch11)\n",
        "    \n",
        "    #10\n",
        "    conv12  = Conv2D(128, kernel_size=3,padding='same')(leaky11)\n",
        "    batch12 = BatchNormalization()(conv12)\n",
        "    leaky12 = LeakyReLU()(batch12)\n",
        "    \n",
        "    #merge\n",
        "    concat1 = concatenate([leaky10, leaky12])\n",
        "    \n",
        "    conv13  = Conv2D(256, kernel_size=3,padding='same')(concat1)\n",
        "    batch13 = BatchNormalization()(conv13)\n",
        "    leaky13 = LeakyReLU()(batch13)\n",
        "    \n",
        "    #output2\n",
        "    conv15  = Conv2D(20, kernel_size=3,padding='same')(leaky13)\n",
        "    batch15 = BatchNormalization()(conv15)\n",
        "    leaky16 = LeakyReLU()(batch15)\n",
        "    \n",
        "    flat2 = Flatten()(leaky16)\n",
        "    hidden3 = Dense(128)(flat2)\n",
        "    leaky17 = LeakyReLU()(hidden3)\n",
        "    \n",
        "    hidden4 = Dense(32)(leaky17)\n",
        "    leaky18 = LeakyReLU()(hidden4)\n",
        "    \n",
        "    output2 = Dense(2)(leaky18)\n",
        "    \n",
        "    #output1\n",
        "#     conv14  = Conv2D(128, kernel_size=3,padding='same')(leaky13)\n",
        "#     batch14 = BatchNormalization()(conv14)\n",
        "#     leaky14 = LeakyReLU()(batch14)\n",
        "    \n",
        "# #     concat2 = concatenate([leaky14, pool5])\n",
        "    \n",
        "#     conv25  = Conv2D(20, kernel_size=3,padding='same')(leaky14)\n",
        "#     batch25 = BatchNormalization()(conv25)\n",
        "#     leaky25 = LeakyReLU()(batch25)\n",
        "    \n",
        "#     flat1 = Flatten()(leaky25)\n",
        "#     hidden1 = Dense(256)(flat1)\n",
        "#     leaky15 = LeakyReLU()(hidden1)\n",
        "    \n",
        "#     hidden2 = Dense(64)(leaky15)\n",
        "#     leaky20 = LeakyReLU()(hidden2)\n",
        "    \n",
        "#     concat2 = concatenate([leaky20, act1])\n",
        "    \n",
        "#     hidden5 = Dense(32)(concat2)\n",
        "#     leaky21 = LeakyReLU()(hidden5)\n",
        "    \n",
        "#     output1 = Dense(2)(leaky21)\n",
        "#     flat0 = Flatten()(leaky25)\n",
        "#     dense0 = Dense(256)(flat0)\n",
        "#     act0 = LeakyReLU()(dense0)\n",
        "    \n",
        "#     dense1 = Dense(64)(act0)\n",
        "#     act1 = LeakyReLU()(dense0)\n",
        "#     dense1 = Dense(32)(act1)\n",
        "#     leaky21 = LeakyReLU()(dense1)\n",
        "    \n",
        "#     output1 = Dense(2)(leaky21)\n",
        "\n",
        "    conv25  = Conv2D(20, kernel_size=3,padding='same')(leaky13)\n",
        "    batch25 = BatchNormalization()(conv25)\n",
        "    leaky26 = LeakyReLU()(batch25)\n",
        "    \n",
        "    flat22 = Flatten()(leaky26)\n",
        "    hidden23 = Dense(128)(flat22)\n",
        "    leaky27 = LeakyReLU()(hidden23)\n",
        "    \n",
        "    hidden24 = Dense(32)(leaky27)\n",
        "    leaky28 = LeakyReLU()(hidden24)\n",
        "    \n",
        "    output1 = Dense(2)(leaky28)\n",
        "    \n",
        "\n",
        "    \n",
        "#     #output3\n",
        "#     conv16  = Conv2D(20, kernel_size=3,padding='same')(leaky5)\n",
        "#     batch16 = BatchNormalization()(conv16)\n",
        "#     leaky17 = LeakyReLU()(batch16)\n",
        "    \n",
        "#     flat3 = Flatten()(leaky17)\n",
        "#     hidden5 = Dense(128)(fla3)\n",
        "#     leaky19 = LeakyReLU()(hidden5)\n",
        "    \n",
        "#     hidden6 = Dense(32)(leaky19)\n",
        "#     leaky20 = LeakyReLU()(hidden6)\n",
        "    \n",
        "#     output3 = Dense(2)(leaky20)\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    model = Model(inputs=visible, outputs=[output1,output2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P7GDd5tVuDCP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Elo7OSouGvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    xi1 = K1.maximum(y_true[0],y_pred[0])\n",
        "    yi1 = K1.maximum(y_true[2],y_pred[2])\n",
        "    xi2 = K1.minimum(y_true[1],y_pred[1])\n",
        "    yi2 = K1.minimum(y_true[3],y_pred[3])\n",
        "    inter_area = (xi2-xi1)*(yi2-yi1)\n",
        "    \n",
        "    \n",
        "    box1_area = (y_true[1]-y_true[0])*(y_true[3]-y_true[2])\n",
        "    box2_area = (y_pred[1]-y_pred[0])*(y_pred[3]-y_pred[2])\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    \n",
        "    iou = inter_area / union_area\n",
        "    \n",
        "    return iou\n",
        "\n",
        "def iou_coef_loss(y_true, y_pred):\n",
        "    return -iou_coef(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ver_5uXUuP_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2gIVlADduToo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(data_t, y, epochs=1,verbose =1, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_I6Wwv8uYGe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parallel_model = multi_gpu_model(model, gpus=4)\n",
        "\n",
        "losses = {\"output1\": \"mean_squared_error\",\"output2\": \"mean_squared_error\"}\n",
        "parallel_model.compile(optimizer='rmsprop', loss=\"mean_squared_error\",metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wIyC0z1GuZfE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parallel_model.fit(data_train, [y_train[:,0:2],y_train[:,2:4]], epochs=20, batch_size=256,validation_split=0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGUdq989ugBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('models/modelt1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GogKIvHSunnm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = parallel_model.predict(data_train[:500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RG9kHnZuuomU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p , p2 = p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ATaIO_ZTur5B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JCwIpvkuu_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7ckiR0tuzyY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r_Yhz0O9u1Cs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(20,80))\n",
        "for i in range(500):\n",
        "    img = np.copy(data_train[i])\n",
        "    img = cv.rectangle(img, \n",
        "                       (int((y_train[i][0] - y_train[i][3]/2)*320*0.5) ,int((y_train[i][1] - y_train[i][2]/2)*240*0.5) ), \n",
        "                       (int((y_train[i][0] + y_train[i][3]/2)*320*0.5), int((y_train[i][1] + y_train[i][2]/2)*240*0.5)), \n",
        "                       (1,0,0), 1)\n",
        "#     img = cv.rectangle(img, \n",
        "#                        (int((p[i][0] - p[i][3]/2)*320*0.5) ,int((p[i][1] - p[i][2]/2)*240*0.5) ), \n",
        "#                        (int((p[i][0] + p[i][3]/2)*320*0.5), int((p[i][1] + p[i][2]/2)*240*0.5)), \n",
        "#                        (0,1,0), 1)\n",
        "#     img = cv.rectangle(img, \n",
        "#                        (int((p2[i][0] - p2[i][3]/2)*320) ,int((p2[i][1] - p2[i][2]/2)*240) ), \n",
        "#                        (int((p2[i][0] + p2[i][3]/2)*320), int((p2[i][1] + p2[i][2]/2)*240)), \n",
        "#                        (0,0,1), 2)\n",
        "    img = cv.rectangle(img, \n",
        "                       (int((p[i][0] - p2[i][1]/2)*320*0.5) ,int((p[i][1] - p2[i][0]/2)*240*0.5) ), \n",
        "                       (int((p[i][0] + p2[i][1]/2)*320*0.5), int((p[i][1] + p2[i][0]/2)*240*0.5)), \n",
        "                       (0,0,1), 1)\n",
        "    plt.subplot(10,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img)\n",
        "    plt.grid('off')\n",
        "    if i == 19:\n",
        "        break\n",
        "    i +=1\n",
        "plt.show()   "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}